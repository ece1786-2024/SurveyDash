The paper "Text Classification via Large Language Models" introduces Clue And Reasoning Prompting (CARP), a novel framework designed to enhance the performance of large language models (LLMs) in text classification tasks. Despite the success of LLMs like GPT-3, they underperform compared to fine-tuned models due to their limited reasoning abilities and token constraints in in-context learning (ICL). CARP addresses these issues by employing a progressive reasoning strategy that first identifies superficial clues in the text and then uses these clues to guide a diagnostic reasoning process for classification. To mitigate token limitations, CARP integrates a fine-tuned model for kNN demonstration search, leveraging both the generalization capabilities of LLMs and task-specific data from a full labeled dataset. CARP achieves state-of-the-art results on four out of five text-classification benchmarks and shows significant promise in low-resource and domain-adaptation scenarios, performing comparably to supervised models with significantly fewer training examples. The paper provides a comprehensive analysis of related work, the construction of prompts, demonstration sampling strategies, and the progressive reasoning strategy employed by CARP. It also presents extensive experimental results, demonstrating CARP's superior performance across various settings and its robustness in domain adaptation. The study concludes with a discussion on the potential future applications of CARP in broader natural language understanding tasks.