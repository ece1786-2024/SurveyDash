The paper "A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges" provides a comprehensive overview of the current state of Legal Judgment Prediction (LJP), an application of Natural Language Processing (NLP) techniques to predict legal case outcomes based on factual descriptions. The survey addresses the gap in existing literature by analyzing 31 LJP datasets in six languages, summarizing 14 evaluation metrics, reviewing 12 legal-domain pretrained models, and discussing the state-of-the-art results for eight representative datasets. The paper highlights the importance of LJP in addressing the imbalance between the need for legal assistance and the availability of legal experts, and discusses the evolution of LJP from rule-based and statistical methods to advanced neural networks and transformer-based models. It categorizes LJP tasks into three attributes: task type, legal system, and law domain, and presents a taxonomy for classifying LJP datasets. The survey also reviews various models and methods used in LJP, including multi-task learning, pre-trained language models, interpretable learning, and few-shot learning. The paper concludes with a discussion on the challenges and recommendations for future LJP research, emphasizing the need for sophisticated datasets from real courtrooms, complex legal reasoning, and adaptive interpretability. The survey serves as a valuable resource for NLP researchers and legal professionals interested in advancing LJP systems.